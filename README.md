# AI Engineering Assistant

> **ğŸš§ MIGRATION IN PROGRESS**  
> This repository is currently undergoing a major migration to integrate AI Architecture Assistant capabilities. The migration is in progress and may affect some functionality. For detailed information about the migration process, timeline, and current status, see [MIGRATION-PLAN.md](MIGRATION-PLAN.md).

Production-ready prompt engineering system that delivers platform-optimized AI prompts through interactive requirements gathering and systematic validation.

## Overview

This project addresses the fundamental challenge of prompt reliability in production AI environments. Built through extensive testing, it delivers measurable improvements in prompt consistency and reduces engineering overhead.

### Two-Tier Architecture

This repository implements a **two-tier prompt engineering system**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TIER 1: CURSOR/COPILOT WORKSPACE (This Repository)     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ System Prompts â†’ Cursor agents you run locally         â”‚
â”‚ User Prompts â†’ Task instructions you send to agents    â”‚
â”‚ Purpose: AI engineering assistance in YOUR IDE         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â”‚ GENERATES
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TIER 2: EXTERNAL DEPLOYMENT (Output Prompts)           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Platforms: OpenAI GPTs â€¢ Claude Projects â€¢ Bedrock     â”‚
â”‚ Purpose: Production AI systems for end users           â”‚
â”‚ Created by: Tier 1 agents in this workspace            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Distinction**:
- **Prompts IN this repo**: Run in Cursor/VS Code as custom agents to help YOU engineer prompts
- **Prompts GENERATED by these agents**: Deploy to external platforms (OpenAI, Claude, etc.) for end users

**Core Innovation**: The Prompt Engineering Assistant agent can progressively improve itself on a schedule based on the latest research and current AI platform capabilities.

## Quick Start

**Set up your Cursor agent and generate your first validated prompt in 5 minutes:**

1. **Download** `ai_agents/prompt_engineering_assistant.system.prompt.md` from this repository
2. **Install as Cursor agent**: Open Cursor Settings â†’ Chat â†’ Custom Modes â†’ Paste content (see Installation section)
3. **Send a task**: "Create a code review assistant for OpenAI GPT" or "Improve my Claude prompt"
4. **Answer 2-3 quick questions**: Target platform for generated prompt, optimization focus
5. **Receive validated output**: Copy-paste ready prompt for external deployment with character count

The agent progressively gathers only essential requirements, letting you work at your preferred speed.

**What you're creating**: Prompts for deployment to OpenAI, Claude, Bedrock, etc.  
**Where you're working**: In Cursor AI Pane, using this repo's agent

**Need more clarity?** See [ARCHITECTURE.md](ARCHITECTURE.md) for detailed two-tier system explanation

## Interactive Workflow in Action

Experience how the Cursor agent prevents deployment failures through intelligent requirements gathering:

```markdown
You (in Cursor AI Pane): "Create a code review assistant"

Agent: "I'll help you create a code review assistant. To optimize for your needs:

Which platform will this be deployed to?
- OpenAI GPT (~1,500 chars)
- Anthropic Claude (~32,000 chars)
- AWS Bedrock
- Other (please specify)"

You: "GPT"

Agent: "For a code review assistant on GPT, I'll create a concise prompt.
Any specific focus areas? (security, performance, style, or I'll determine)"

You: "Focus on security"

Agent: "Creating security-focused code review assistant for GPT deployment...

[Generates complete prompt ready for OpenAI custom instructions]
[1,423 / 1,500 characters]"
```

The agent asks only what's necessaryâ€”if you provide an existing prompt, it infers domain and complexity automatically.

**Clarification**: You're chatting with the Cursor agent in YOUR workspace. The agent generates prompts for EXTERNAL platform deployment.

## Technical Innovation

### Interactive Requirements Architecture

This system pioneered **conversational requirements gathering** that prevents the #1 cause of prompt deployment failures: platform incompatibility.

**Key Innovations**:

- **Progressive Interaction Model**: Gathers requirements in logical clusters, asking only what's necessary
- **Platform-Aware Optimization**: Hard-coded character limits for major platforms prevent overflow failures
- **Smart Inference Engine**: Analyzes existing prompts to skip redundant questions, respecting engineer time
- **Risk Transparency**: Clearly communicates consequences of missing requirements without blocking progress

### Enhanced 5-Step Methodology

1. **Interactive Requirements**: Conversational gathering of platform, domain, and optimization preferences
2. **Research Phase**: Platform-specific analysis using empirical data and current best practices
3. **Multi-Path Testing**: Validation scaled to domain sensitivity (healthcare: comprehensive, creative: minimal)
4. **Systematic Enhancement**: Optimization focused on gathered requirements and platform constraints
5. **Final Confirmation**: Character count validation and platform compatibility verification

### Advanced Engineering Features

- **Dual-Persona Architecture**: Prompt Builder creates, Prompt Tester validatesâ€”systematic quality assurance
- **Tree-of-Thoughts Processing**: Evaluates multiple solution paths simultaneously for optimal design
- **Self-Consistency Validation**: Multiple reasoning paths ensure robust, production-ready outputs
- **Platform Feature Mapping**: Automatically adapts to leverage platform-specific capabilities

## Cohesive Prompt System Architecture

This repository implements a sophisticated **three-layer agent system** running IN Cursor/VS Code to help you engineer prompts FOR external platforms:

### Layer 1: Core Engine (System Prompt)
**File**: `ai_agents/prompt_engineering_assistant.system.prompt.md`  
**Runs**: As Cursor Custom Mode / VS Code Chat Mode  
**Purpose**: Your primary prompt engineering agent

The foundational Cursor agent featuring **interactive requirements gathering** and **dual-persona validation**:

- **Interactive Workflow**: Progressive requirements gathering for prompts you're creating
- **Platform Intelligence**: Built-in character limits for target platforms (OpenAI, Claude, Bedrock, etc.)
- **Prompt Builder**: Creates platform-optimized prompts for external deployment
- **Prompt Tester**: Validates generated outputs against target platform constraints
- **Smart Inference**: Minimizes questions by analyzing your existing prompt content

**Usage**: Install in Cursor, then send tasks like "Create a code review GPT" or "Optimize my Claude prompt"

### Layer 2: Self-Enhancement (User Prompt)
**File**: `user_prompts/prompt_engineering/improve_prompt_engineering_assistant.user.prompt.md`  
**Sent to**: The Cursor agent (Layer 1)  
**Purpose**: Instruct the agent to improve itself

Meta-prompt enabling the agent to **systematically improve itself**:

- **Empirical Analysis**: Research-driven identification of agent enhancement opportunities
- **Backward Compatibility**: Preserves all existing agent functionality while adding capabilities
- **Validation Requirements**: Rigorous testing ensuring agent improvements deliver value
- **Bootstrap Enhancement**: Each improvement increases the agent's self-improvement capability

**Usage**: Attach this user prompt in Cursor to trigger agent self-improvement cycle

### Layer 3: System Coordination (User Prompt)
**File**: `user_prompts/prompt_engineering/improve_system_of_prompts.user.prompt.md`  
**Sent to**: The Cursor agent (Layer 1)  
**Purpose**: Optimize multiple prompts as a coordinated system

Instructs the agent to orchestrate **multi-prompt optimization**:

- **Redundancy Detection**: Identifies duplicates across your prompt library
- **Information Flow Optimization**: Ensures logical distribution of responsibilities
- **Dependency Management**: Maintains clear execution order across prompt systems
- **System Validation**: Comprehensive testing of prompt interaction patterns

**Usage**: Attach this user prompt + your prompt files in Cursor to optimize your entire prompt library

### Integration Benefits

This three-layer architecture delivers measurable engineering value:
- **Centralized workspace**: All prompt engineering happens in Cursor/VS Code
- **Target platform optimization**: Generated prompts work perfectly on OpenAI, Claude, Bedrock, etc.
- **Self-improving capability**: Agent can enhance itself based on latest research
- **System-level optimization**: Manage complex multi-prompt workflows efficiently
- **Production-ready outputs**: Copy-paste ready prompts with character count validation

## Installation and Configuration

**Important**: These installation steps set up agents IN YOUR IDE (Cursor/VS Code). These agents then help you create prompts for deployment TO external platforms (OpenAI, Claude, Bedrock, etc.).

### For Cursor (Recommended)

**Purpose**: Install the Prompt Engineering Assistant as a Cursor agent in your workspace

1. Download `ai_agents/prompt_engineering_assistant.system.prompt.md` from this repository
2. Open Cursor Settings â†’ Chat â†’ Custom Modes
3. Click "New Mode" and name it "Prompt Engineering Assistant"  
4. Select "All tools enabled"
5. Paste the entire file contents into Instructions
6. Save and select from the dropdown in any chat
7. **Start using**: Send tasks like "Create a GPT for code review" or "Improve my Claude prompt"

### For VS Code / GitHub Copilot

**Purpose**: Install the agent as a VS Code custom chat mode

1. The workspace includes a ready-to-use mode: `.github/chatmodes/prompt_engineering_assistant.chatmode.md`
2. Open Chat (âŒƒâŒ˜I) â†’ Select "Prompt Engineering Assistant" mode from the dropdown
3. Tools: ensure `codebase`, `search`, `fetch`, and (if available) `websearch` are enabled
4. Use default Prompt Builder persona; explicitly request Prompt Tester when validating
5. **Start using**: Send user prompts from the `user_prompts/` directory

### Using Github Copilot Coding Agent (For Recursive Self-Improvement)

**Purpose**: Automate iterative improvements to the agents themselves

- **Handoff to Copilot Coding Agent**:
  - Create a new issue using template "Prompt Improvement: Copilot Agent" and assign to `github-copilot-agent`
  - Or paste `#github-pull-request_copilot-coding-agent` in VS Code chat
  - Agent creates a branch and PR, iterates based on your review comments

- **Scheduled Upkeep** (Optional):
  - Weekly workflow: `.github/workflows/copilot-prompt-improvement.yml` (Mondays 14:00 UTC)
  - Opens/updates improvement issues assigned to the agent
  - Run on demand via Actions tab with custom inputs

### Advanced: Running Agent Prompts in Other Platforms

**Not recommended but possible**: While these agents are optimized for Cursor/Copilot with tool access, you can run them in Claude Projects or ChatGPT as custom instructions. Functionality will be limited without file access and search capabilities. This defeats the purposeâ€”use them in Cursor/VS Code instead.

## Implementation Examples

These examples show the Cursor agent in action, creating prompts for external platform deployment.

### Platform Migration: GPT to Claude

**Challenge**: Marketing team's customer analysis prompt exceeded OpenAI's 1,500 character limit

**Workflow in Cursor**:

```markdown
You (in Cursor AI Pane): "Improve my customer segmentation prompt"
[Attach existing prompt file]

Agent: "I'll help you improve this prompt. Which platform will this be deployed to?"

You: "OpenAI GPT"

Agent: "Your current prompt is 3,200 characters. For GPT's ~1,500 limit, I'll:
       1. Extract examples to external documentation
       2. Compress instructions using structured format
       3. Maintain all functionality"

[Agent generates optimized prompt]
Result: [1,487 / 1,500 characters] - Ready for GPT deployment
```

**Impact**: 100% deployment success rate, 0% functionality loss, 54% size reduction

**What happened**: You used the Cursor agent to optimize a prompt FOR deployment TO OpenAI GPT

### Healthcare Diagnostic Assistant

**Challenge**: Medical AI prompt required comprehensive testing due to domain sensitivity

**Workflow in Cursor**:

```markdown
You (in Cursor AI Pane): "Create a symptom analysis assistant for Claude"

Agent: "I'll create a healthcare assistant. Given the medical domain, I'll apply 
       comprehensive validation and safety constraints.
       
       Which specific aspects should it focus on? (triage, education, referral)"

You: "Patient education and when to seek care"

Agent: [Generates prompt with safety guardrails]
       â†’ Comprehensive testing for medical edge cases
       â†’ Safety constraint verification
       â†’ Explicit limitations and disclaimers
       
Result: Production-ready prompt for Claude Projects deployment
```

**Impact**: Medical-grade validation preventing misdiagnosis scenarios, ready for Claude deployment

**What happened**: You used the Cursor agent to create a healthcare prompt FOR deployment TO Claude Projects

### Multi-Prompt System Optimization

**Challenge**: Token inefficiency and redundant context across related prompts in your prompt library

**Workflow in Cursor**:

```markdown
You (in Cursor AI Pane): [Send user_prompts/prompt_engineering/improve_system_of_prompts.user.prompt.md]
                         [Attach your 3 technical documentation prompts]

Agent: [Analyzes prompt system]
       â†’ Identifies redundancies across prompts
       â†’ Proposes consolidation strategy
       â†’ Validates optimized system
       
Result: 27% token reduction, clearer separation of concerns, all functionality preserved
```

**Impact**: More efficient prompt library, faster execution, maintained functionality

**What happened**: You used the Cursor agent's system optimization capabilities to improve prompts in YOUR library (which may be deployed anywhere)

## System Requirements and Architecture

### Platform Compatibility

**Where This Repository's Agents Run (Tier 1)**:

- **Cursor** âœ“ Complete feature set with tool integration (recommended)
- **VS Code / GitHub Copilot** âœ“ Full functionality with custom chat modes
- **Other platforms** âš ï¸ Not recommended (no file/workspace access)

**Where Generated Prompts Deploy (Tier 2)**:

- **OpenAI Custom GPTs** - Character limit: ~1,500
- **Anthropic Claude Projects** - Character limit: ~32,000
- **AWS Bedrock Agents** - Varies by model
- **Google Gemini** - Character limit: ~4,000
- **Other Cursor/Copilot agents** - Character limit: ~8,000
- **Perplexity, Mistral, and more** - Platform-specific optimization

**Agent Requirements (Tier 1)**:

- File system access for reading prompts and workspace files
- Search capabilities for research and analysis
- Multi-turn conversation for interactive requirements gathering
- Tool execution for validation and testing

### Performance Benchmarks

**Prompt Generation Efficiency**:

- **Initial Prompt Creation**: Faster than manual engineering
- **Validation Cycle Time**: Reduction through systematic testing  
- **Cross-Platform Deployment**: Zero additional configuration required

**Quality Metrics**:

- **Consistency Score**: Across repeated executions
- **Validation Coverage**: Through dual-persona architecture
- **Production Success Rate**: Deployment reliability

### Deployment Considerations

**Variable-Driven Architecture**:

- **Core Variables**: 10 system variables drive all optimization decisions
- **Requirements Storage**: ~200 tokens for complete requirement set
- **Platform Constraints**: Automatic adaptation to target platform limits
- **Smart Defaults**: 85% of variables can be inferred or use intelligent defaults

**Token Optimization**:

- System prompt length: ~16,800 characters (comprehensive functionality)
- It can rewrite itself to be platform-specific by reducing its own character count
- Interactive overhead: <100 tokens for typical requirement gathering
- Output optimization: Automatic compression for character-limited platforms

**Security and Compliance**:

- No external API dependencies or data transmission
- Full transparency in requirement collection
- Compatible with enterprise AI governance and audit requirements

## Advanced Configuration

### Multi-Prompt System Optimization

For complex workflows requiring multiple coordinated prompts:

1. **System Analysis**: Use `user_prompts/prompt_engineering/improve_system_of_prompts.user.prompt.md` to analyze prompt interactions
2. **Redundancy Detection**: Identify and eliminate duplicate context across prompts  
3. **Information Flow Optimization**: Ensure logical distribution of responsibilities
4. **Validation Testing**: Comprehensive testing of prompt coordination patterns

### Enterprise Integration Patterns

**Team Deployment**:

- Standardize prompt templates across engineering teams
- Implement validation protocols for prompt quality assurance
- Establish continuous improvement workflows

**Production Optimization**:

- Monitor prompt performance metrics and consistency scores
- Implement A/B testing for prompt variations
- Maintain prompt versioning and rollback capabilities

## Troubleshooting and Support

### Common Interactive Workflow Issues

**Agent asks too many questions**: Provide context upfront. The agent infers requirements from existing prompts and clear initial requests like "Create a code review GPT" or "Improve my Claude prompt for healthcare".

**Generated prompt exceeds character limit**: The agent automatically suggests optimizations for the target platform. Accept compression suggestions or request a different deployment platform with higher limits.

**Wrong target platform**: Say "Actually, I need this deployed to [platform]" and the agent will re-optimize the generated prompt for that platform.

**Agent doesn't have file access**: Ensure you're running in Cursor or VS Code with proper tool permissions. The agent needs file system access to read and optimize prompts.

### Platform Configuration

**Cursor Setup**: Enable "All tools" in Custom Mode settings for full capabilities (file reading, search, web research)

**VS Code Setup**: Ensure tools (`codebase`, `search`, `fetch`, `websearch`) are enabled in chat mode configuration

**Generated Prompt Deployment**: Copy generated prompts directly to target platform (OpenAI, Claude, Bedrock, etc.)

### Architecture Questions

**Confused about two-tier system?** See [ARCHITECTURE.md](ARCHITECTURE.md) for complete explanation

**Where does what run?** Agents run IN Cursor/VS Code (this repo). Generated prompts deploy TO external platforms (OpenAI, Claude, etc.)

## Contributing and License

**License**: MIT - Full commercial and enterprise usage permitted

**Contributing**: Improvements welcomeâ€”ensure agents remain fast, interactive workflow is smooth, and platform limits stay current

**Engineering Philosophy**: Iterate often. Maintain maintainability. Demand simplicity. Respect engineer time. Prevent deployment failures. Optimize for every platform.

**Architecture Documentation**: See [ARCHITECTURE.md](ARCHITECTURE.md) for detailed system design and two-tier architecture explanation

**Repository**: [AI Engineering Assistant](https://github.com/Modular-Earth-LLC/AI-engineering-assistant) - Production-ready Cursor/VS Code agents for systematic prompt engineering and deployment to external AI platforms.
